{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a212eff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'user_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Execute the analysis\u001b[39;00m\n\u001b[1;32m     91\u001b[0m cleaned_data \u001b[38;5;241m=\u001b[39m user_analysis\u001b[38;5;241m.\u001b[39mclean_and_preprocess()\n\u001b[0;32m---> 92\u001b[0m aggregated_data \u001b[38;5;241m=\u001b[39m user_analysis\u001b[38;5;241m.\u001b[39maggregate_user_behaviour()\n\u001b[1;32m     93\u001b[0m top_10_handsets \u001b[38;5;241m=\u001b[39m user_analysis\u001b[38;5;241m.\u001b[39mtop_10_handsets()\n\u001b[1;32m     94\u001b[0m top_3_manufacturers \u001b[38;5;241m=\u001b[39m user_analysis\u001b[38;5;241m.\u001b[39mtop_3_manufacturers()\n",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m, in \u001b[0;36mUserOverviewAnalysis.aggregate_user_behaviour\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate_user_behaviour\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Placeholder for user behaviour aggregation\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Implement your logic to aggregate user behavior\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     aggregated_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmydata\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()  \u001b[38;5;66;03m# Replace this with your actual aggregation logic\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m aggregated_data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8870\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8871\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[1;32m   8872\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   8873\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   8874\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[1;32m   8875\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   8876\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[1;32m   8877\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   8878\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   8879\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[1;32m   1279\u001b[0m         obj,\n\u001b[1;32m   1280\u001b[0m         keys,\n\u001b[1;32m   1281\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   1282\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   1283\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   1284\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[1;32m   1285\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[1;32m   1286\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'user_id'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "class UserOverviewAnalysis:\n",
    "    def __init__(self, mydata):\n",
    "        self.mydata = mydata\n",
    "\n",
    "    def clean_and_preprocess(self):\n",
    "        # Placeholder for data cleaning and preprocessing logic\n",
    "        # Implement your logic to clean and preprocess the data\n",
    "        cleaned_data = self.mydata  # Replace this with your actual cleaning/preprocessing logic\n",
    "        return cleaned_data\n",
    "\n",
    "    def visualize_results(self):\n",
    "        # Common visualization logic that can be reused\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        # Placeholder plotting logic\n",
    "        # Implement your visualization logic\n",
    "        plt.show()\n",
    "\n",
    "    def aggregate_user_behaviour(self):\n",
    "        # Placeholder for user behaviour aggregation\n",
    "        # Implement your logic to aggregate user behavior\n",
    "        aggregated_data = self.mydata.groupby('user_id').sum()  # Replace this with your actual aggregation logic\n",
    "        return aggregated_data\n",
    "\n",
    "    def top_10_handsets(self):\n",
    "        # Placeholder for identifying top 10 handsets\n",
    "        # Implement your logic to identify the top 10 handsets\n",
    "        top_10_handsets = self.mydata['handset_model'].value_counts().head(10)  # Replace this with your actual logic\n",
    "        return top_10_handsets\n",
    "\n",
    "    def top_3_manufacturers(self):\n",
    "        # Placeholder for identifying top 3 handset manufacturers\n",
    "        # Implement your logic to identify the top 3 manufacturers\n",
    "        top_3_manufacturers = self.mydata['manufacturer'].value_counts().head(3)  # Replace this with your actual logic\n",
    "        return top_3_manufacturers\n",
    "\n",
    "    def top_5_handsets_per_manufacturer(self):\n",
    "        # Placeholder for identifying top 5 handsets per top 3 handset manufacturer\n",
    "        # Implement your logic to identify the top 5 handsets per top 3 manufacturers\n",
    "        top_manufacturers = self.top_3_manufacturers().index\n",
    "        top_5_handsets_per_manufacturer = (\n",
    "            self.mydata[self.mydata['manufacturer'].isin(top_manufacturers)]\n",
    "            .groupby(['manufacturer', 'handset_model'])\n",
    "            .size()\n",
    "            .groupby('manufacturer', group_keys=False)\n",
    "            .nlargest(5)\n",
    "        )  # Replace this with your actual logic\n",
    "        return top_5_handsets_per_manufacturer\n",
    "\n",
    "    def data_analysis(self):\n",
    "        # Example: Analyze and visualize the distribution of session durations for each application\n",
    "        applications = ['SocialMediaData', 'GoogleData', 'EmailData', 'YoutubeData', 'NetflixData', 'GamingData', 'OtherData']\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for app in applications:\n",
    "            sns.histplot(self.mydata[self.mydata[app] > 0]['SessionDuration'], label=app, kde=True)\n",
    "\n",
    "        plt.title('Distribution of Session Durations for Each Application')\n",
    "        plt.xlabel('Session Duration')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    'dbname': 'week1',\n",
    "    'user': 'postgres',\n",
    "    'password': 'habte',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_params[\"user\"]}:{db_params[\"password\"]}@{db_params[\"host\"]}:{db_params[\"port\"]}/{db_params[\"dbname\"]}')\n",
    "\n",
    "# SQL query to retrieve data\n",
    "sql_query = \"SELECT * FROM xdr_data;\"\n",
    "\n",
    "# Read data from PostgreSQL into a DataFrame\n",
    "mydata = pd.read_sql_query(sql_query, engine)\n",
    "\n",
    "# Create an instance of UserOverviewAnalysis with the actual data\n",
    "user_analysis = UserOverviewAnalysis(mydata)\n",
    "\n",
    "# Execute the analysis\n",
    "cleaned_data = user_analysis.clean_and_preprocess()\n",
    "aggregated_data = user_analysis.aggregate_user_behaviour()\n",
    "top_10_handsets = user_analysis.top_10_handsets()\n",
    "top_3_manufacturers = user_analysis.top_3_manufacturers()\n",
    "top_5_handsets_per_manufacturer = user_analysis.top_5_handsets_per_manufacturer()\n",
    "user_analysis.visualize_results()\n",
    "user_analysis.data_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a36ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
